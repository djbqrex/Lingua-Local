# Language Learning Assistant Configuration

# ==========================================
# Hardware Configuration
# ==========================================

# Device to use: cuda, cpu, or auto (auto-detect GPU)
DEVICE=auto

# Compute type: float16 (GPU), int8 (CPU), or float32
COMPUTE_TYPE=float16

# ==========================================
# Model Configuration
# ==========================================

# Speech-to-Text Model
# Options: tiny, base, small, medium, large-v3
# Recommended: base/small for CPU, medium/large for GPU
STT_MODEL=small

# Language Model
# Options: qwen2.5-0.5b-instruct, qwen2.5-1.5b-instruct, qwen2.5-3b-instruct
# Recommended: 1.5b for most use cases
LLM_MODEL=qwen2.5-1.5b-instruct

# Text-to-Speech Voice
# Format: language_code-voice-quality
# Examples: en_US-lessac-medium, es_ES-davefx-medium, fr_FR-siwis-medium
TTS_VOICE=en_US-lessac-medium

# ==========================================
# Language Support
# ==========================================

# Comma-separated list of supported language codes
SUPPORTED_LANGUAGES=en,es,fr,de,it,pt,ja,zh,ko,ar

# ==========================================
# Performance Settings
# ==========================================

# Maximum audio length in seconds
MAX_AUDIO_LENGTH=30

# Stream audio responses (true/false)
STREAM_AUDIO=true

# Cache loaded models in memory (true/false)
CACHE_MODELS=true

# Maximum conversation context length (number of messages)
MAX_CONTEXT_LENGTH=10

# ==========================================
# API Configuration
# ==========================================

# Host to bind to
HOST=0.0.0.0

# Port to listen on
PORT=8000

# CORS origins (comma-separated)
CORS_ORIGINS=http://localhost:8080,http://127.0.0.1:8080

# ==========================================
# Logging
# ==========================================

# Log level: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO
