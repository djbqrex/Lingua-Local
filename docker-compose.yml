version: '3.8'

services:
  language-assistant:
    image: lingua-local:latest
    build:
      context: .
      dockerfile: backend/Dockerfile
      args:
        USE_GPU: "false"  # Set to "true" for GPU support
    container_name: language-learning-assistant
    ports:
      - "8080:8000"
    volumes:
      - ./models:/app/models
      - ./backend:/app/backend
      - ./frontend:/app/frontend
      - ./tmp:/app/tmp
    environment:
      # Hardware
      - DEVICE=auto
      - COMPUTE_TYPE=float16
      
      # Models
      - STT_MODEL=small
      - LLM_MODEL=qwen2.5-1.5b-instruct
      - TTS_VOICE=en_US-lessac-medium
      
      # Languages
      - SUPPORTED_LANGUAGES=en,es,fr,de,it,pt,ja,zh,ko,ar
      
      # Performance
      - MAX_AUDIO_LENGTH=30
      - STREAM_AUDIO=true
      - CACHE_MODELS=true
      
      # API
      - HOST=0.0.0.0
      - PORT=8000
      - CORS_ORIGINS=http://localhost:8080,http://127.0.0.1:8080
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    # Resource limits (adjust based on your hardware)
    deploy:
      resources:
        limits:
          memory: 8G
        reservations:
          memory: 4G

volumes:
  models:
    driver: local
